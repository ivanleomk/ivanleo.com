---
title: Machine Learning Roadmap
date: 2023-05-14
categories:
  - Machine Learning
  - FastAI
  - Deep Learning
description: I'm planning to break into the ML side of things - here's what I have in mind.
draft: true
---

## Background

Looking to break into ML and I kind of lose track of what I've been doing so I figured I'd just document everything here.


## The Progress

### August 

- Finished tidying up a [repo](https://github.com/ivanleomk/Zero-To-Hero-notes) with notes that I'd taken down on Karpathy's course. Currently we have part 1,2 and 3 in there.
- Read up a bit on the paper that he mentioned - [A Neural Probablistic Model](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf) which mentions the use of a real-number vector to represent words. This is currently used extensively in NLP and is known as word embeddings but back then I'm sure it must have been a novel idea. 
- Signed up for Buildspace to build a small tool to help people prep for interviews using GPT-4 and some other models.
- Played around with the new Next Auth Kysely integration and Resend and wrote a quick article [here](blog/implementing_magic_links_with_resend_kysely_and_next_auth)

Goal for the remainder of the month is to experiment with GPT-4 and to build some POCs with embeddings and whisper :)

### July 

I wasn't able to do as much as I wanted due to reservice commitments but I did manage to get a few things done.

- Discovered Andrej Karpathy's [Zero to Hero course](https://karpathy.ai/zero-to-hero.html) and plan to start working through it through August. So far I've finished up with his intro to neural networks and I built a basic binary classifier which has ~42% accuracy using a custom neural network I coded in vanila python. Finished up with the first 2 chapters of his course and I'm really enjoying it so far.

- Finally figured out how to deploy [langchain on AWS lambda](blog/ci_cd_with_langchain_aws_lambda_using_docker_image) and spent my entire weekend trying to automate a 20 min task with aws sdk 

### June

June has just started and my plan now is to work on more applications of LLMs. I believe that using LLMs to augment my learning will help tremendously when it comes to generating new insights and finding interesting angles to explore. 

The plan is to build a local LLM using gpt to be able to query and discover new insights about my previous notes and chats. I tried implementing a basic clone with memory and embeddings [here](blog/why_use_chat_gpt_when_you_can_build_your_own_) but ended up getting side tracked with other ideas.

I also started experimenting with Open AI Functions and built out a simple classifier using Yake and GPT that was able to classify places that I had been to before using my reviews and other metadata ( [Link](blog/crawling_your_saved_places_with_google_maps) )


### May

I've managed to finish up Part 1 of Fast AI's course and boy have I learnt a lot about machine learning in general. The course seems to cover a lot more of traditional machine learning techniques and there's a lot which I'll definitely need to revisit.  You can read my notes here [FastAI Part 1](/blog/notes_on_fast_ai)

