{
  "title": "Whispers In The Background",
  "date": "2023-05-01T00:00:00.000Z",
  "description": "A first stab at an architecture that allows for transcripts to be generated for user uploads",
  "categories": [
    "OpenAI",
    "ML",
    "Whisper",
    "MLE"
  ],
  "body": {
    "raw": "\n<KommyImage blogImage={true} src = \"https://user-images.githubusercontent.com/45760326/235455711-4dd33dde-88f9-456f-b5b5-c1c26e638576.png\" width = {400} height = {400} />\n\n## Introduction\n\nI recently ran into two problems when trying to generate transcript for audio files using whisper when working with NextJS\n\n1. They were taking too long and the request would time out \n2. The files were too large and I couldn't send them through the request body of a api route \n\nIf you're not familiar with NextJS deployed on Vercel, there are two limits that they place on your functions - they have to finish executing in at most 30s and the request body can't be larger than 4.5MB. You can try overriding body parser to take maybe 8mb of data but that's not a good idea since large audio files are often significantly larger than that.\n\nI decided to try and solve this problem by using a long-running docker container which would act as a server and would be able to handle large files. I also decided to use a queue to handle the requests so that I could handle multiple requests at once.\n\n### Database-as-a-Queue\n\n<b>Here's the kicker - my database is my queue.</b>\n\nI was inspired by [this article](https://www.prequel.co/blog/sql-maxis-why-we-ditched-rabbitmq-and-replaced-it-with-a-postgres-queue) I had read a while ago about how they had replaced RabbitMQ with Postgres and thought I'd be able to give it a shot too. \n\nI came up with the following schema for a table which would be able to serve as our queue.\n\n<KommyImage src = \"https://user-images.githubusercontent.com/45760326/235456606-13ec3fb4-43da-4a10-ba62-89b275464b17.png\" width = {400} height = {400} />\n\nLet's walk through a few important columnns.\n\n<Callout>\nNote, I'm using ID because planetscale prevents the use of strings as primary keys\n</Callout>\n\n1. `isProcesing` : This variable helps tell us when we started processing an item and how long it has been stuck processing an item for.\n2. `isProcessed` : This variable tells us if the item has been processed or not. \n3. `isTranscribed` : This variable tells us whether an item has been processed or not.\n4. `startedProcessing`: This is a timestamp which tells us exactly when we started processing the current file.\n\nSo how do these variables help to ensure we have a queue?\n\n1. When a docker instance picks a item from the list to process, it sets `isProcessing` to true and sets the `processingStartedAt` to the current time. If another docker container happens to pick it up at the same time, it will see `isProcessing` has been set to true and abandon the job.\n\n2. If it accidentally crashes or is unable to finish the processing, we have the `startedProcessing` variable to tell us when exactly processing started. We can then specify a threshold, after which another docker instance can pick up the job even if `isProcessing` is set to true.\n\n3. if the file has already been transcribed, we can just end the job early.\n\nWe can visualise this using a flowchart as seen below \n\n<KommyImage src = \"https://user-images.githubusercontent.com/45760326/235459095-efba6b62-27c9-460c-abfc-09c154a4a4bf.png\" blogImage = {true} height = {400} width = {400} alt = \"Decision Diagram for Server\" />\n\nEach of these jobs will always be completed by adding a cron job down the line which takes all the outstanding files which have been processing for more than a certain amount of time and sends them to be processed.\n\nWe can express this in psuedocode as follows\n\n```python\n# Get All Files that have isProcessing=false OR (isProcessing=True and startedProcessingAt > 30 minutes ago)\n```\n\nI might also add a retry counter which will help track the number of times a file has been attempted to be processed and if it has failed too many times, we can just mark it as failed and move on. Errors can then be shown to the user who might have uploaded a corrupted file.\n\n### Fault Tolerance\n\nI built this to tolerate two main kinds of faults\n\n1. Docker Containers going down - If a file is being processed midway and our docker container dies, a cron job will identify all the files that need to be processed easily and retry them \n\n2. File Information being captured - we capture a succesful upload at two different locations. The first is on the user's side after they get notified that they have a succesful upload. The second is on that of AWS S3. By adding in a trigger to automatically start processing the file upon uploading it to S3, we can ensure that we have a backup of the file in case something goes wrong.\n\n\n That's a quick writeup on what I found most interesting about this specific project. I'll be writing a more detailed post about how I built this and certain parts in the future so stay tuned!",
    "code": "var Component=(()=>{var dn=Object.create;var j=Object.defineProperty;var cn=Object.getOwnPropertyDescriptor;var mn=Object.getOwnPropertyNames;var fn=Object.getPrototypeOf,bn=Object.prototype.hasOwnProperty;var G=(u,r)=>()=>(r||u((r={exports:{}}).exports,r),r.exports),_n=(u,r)=>{for(var f in r)j(u,f,{get:r[f],enumerable:!0})},Ne=(u,r,f,p)=>{if(r&&typeof r==\"object\"||typeof r==\"function\")for(let y of mn(r))!bn.call(u,y)&&y!==f&&j(u,y,{get:()=>r[y],enumerable:!(p=cn(r,y))||p.enumerable});return u};var hn=(u,r,f)=>(f=u!=null?dn(fn(u)):{},Ne(r||!u||!u.__esModule?j(f,\"default\",{value:u,enumerable:!0}):f,u)),pn=u=>Ne(j({},\"__esModule\",{value:!0}),u);var xe=G((xn,we)=>{we.exports=React});var Ce=G(K=>{\"use strict\";(function(){\"use strict\";var u=xe(),r=Symbol.for(\"react.element\"),f=Symbol.for(\"react.portal\"),p=Symbol.for(\"react.fragment\"),y=Symbol.for(\"react.strict_mode\"),z=Symbol.for(\"react.profiler\"),X=Symbol.for(\"react.provider\"),H=Symbol.for(\"react.context\"),R=Symbol.for(\"react.forward_ref\"),I=Symbol.for(\"react.suspense\"),F=Symbol.for(\"react.suspense_list\"),T=Symbol.for(\"react.memo\"),A=Symbol.for(\"react.lazy\"),Ue=Symbol.for(\"react.offscreen\"),J=Symbol.iterator,ke=\"@@iterator\";function Pe(e){if(e===null||typeof e!=\"object\")return null;var n=J&&e[J]||e[ke];return typeof n==\"function\"?n:null}var w=u.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;function b(e){{for(var n=arguments.length,t=new Array(n>1?n-1:0),a=1;a<n;a++)t[a-1]=arguments[a];Se(\"error\",e,t)}}function Se(e,n,t){{var a=w.ReactDebugCurrentFrame,l=a.getStackAddendum();l!==\"\"&&(n+=\"%s\",t=t.concat([l]));var d=t.map(function(o){return String(o)});d.unshift(\"Warning: \"+n),Function.prototype.apply.call(console[e],console,d)}}var Oe=!1,je=!1,Ie=!1,Fe=!1,Ae=!1,Q;Q=Symbol.for(\"react.module.reference\");function We(e){return!!(typeof e==\"string\"||typeof e==\"function\"||e===p||e===z||Ae||e===y||e===I||e===F||Fe||e===Ue||Oe||je||Ie||typeof e==\"object\"&&e!==null&&(e.$$typeof===A||e.$$typeof===T||e.$$typeof===X||e.$$typeof===H||e.$$typeof===R||e.$$typeof===Q||e.getModuleId!==void 0))}function Me(e,n,t){var a=e.displayName;if(a)return a;var l=n.displayName||n.name||\"\";return l!==\"\"?t+\"(\"+l+\")\":t}function Z(e){return e.displayName||\"Context\"}function v(e){if(e==null)return null;if(typeof e.tag==\"number\"&&b(\"Received an unexpected object in getComponentNameFromType(). This is likely a bug in React. Please file an issue.\"),typeof e==\"function\")return e.displayName||e.name||null;if(typeof e==\"string\")return e;switch(e){case p:return\"Fragment\";case f:return\"Portal\";case z:return\"Profiler\";case y:return\"StrictMode\";case I:return\"Suspense\";case F:return\"SuspenseList\"}if(typeof e==\"object\")switch(e.$$typeof){case H:var n=e;return Z(n)+\".Consumer\";case X:var t=e;return Z(t._context)+\".Provider\";case R:return Me(e,e.render,\"ForwardRef\");case T:var a=e.displayName||null;return a!==null?a:v(e.type)||\"Memo\";case A:{var l=e,d=l._payload,o=l._init;try{return v(o(d))}catch{return null}}}return null}var N=Object.assign,D=0,ee,ne,re,te,ie,ae,se;function oe(){}oe.__reactDisabledLog=!0;function Ye(){{if(D===0){ee=console.log,ne=console.info,re=console.warn,te=console.error,ie=console.group,ae=console.groupCollapsed,se=console.groupEnd;var e={configurable:!0,enumerable:!0,value:oe,writable:!0};Object.defineProperties(console,{info:e,log:e,warn:e,error:e,group:e,groupCollapsed:e,groupEnd:e})}D++}}function Le(){{if(D--,D===0){var e={configurable:!0,enumerable:!0,writable:!0};Object.defineProperties(console,{log:N({},e,{value:ee}),info:N({},e,{value:ne}),warn:N({},e,{value:re}),error:N({},e,{value:te}),group:N({},e,{value:ie}),groupCollapsed:N({},e,{value:ae}),groupEnd:N({},e,{value:se})})}D<0&&b(\"disabledDepth fell below zero. This is a bug in React. Please file an issue.\")}}var W=w.ReactCurrentDispatcher,M;function U(e,n,t){{if(M===void 0)try{throw Error()}catch(l){var a=l.stack.trim().match(/\\n( *(at )?)/);M=a&&a[1]||\"\"}return`\n`+M+e}}var Y=!1,k;{var $e=typeof WeakMap==\"function\"?WeakMap:Map;k=new $e}function le(e,n){if(!e||Y)return\"\";{var t=k.get(e);if(t!==void 0)return t}var a;Y=!0;var l=Error.prepareStackTrace;Error.prepareStackTrace=void 0;var d;d=W.current,W.current=null,Ye();try{if(n){var o=function(){throw Error()};if(Object.defineProperty(o.prototype,\"props\",{set:function(){throw Error()}}),typeof Reflect==\"object\"&&Reflect.construct){try{Reflect.construct(o,[])}catch(g){a=g}Reflect.construct(e,[],o)}else{try{o.call()}catch(g){a=g}e.call(o.prototype)}}else{try{throw Error()}catch(g){a=g}e()}}catch(g){if(g&&a&&typeof g.stack==\"string\"){for(var s=g.stack.split(`\n`),_=a.stack.split(`\n`),c=s.length-1,m=_.length-1;c>=1&&m>=0&&s[c]!==_[m];)m--;for(;c>=1&&m>=0;c--,m--)if(s[c]!==_[m]){if(c!==1||m!==1)do if(c--,m--,m<0||s[c]!==_[m]){var h=`\n`+s[c].replace(\" at new \",\" at \");return e.displayName&&h.includes(\"<anonymous>\")&&(h=h.replace(\"<anonymous>\",e.displayName)),typeof e==\"function\"&&k.set(e,h),h}while(c>=1&&m>=0);break}}}finally{Y=!1,W.current=d,Le(),Error.prepareStackTrace=l}var C=e?e.displayName||e.name:\"\",ye=C?U(C):\"\";return typeof e==\"function\"&&k.set(e,ye),ye}function qe(e,n,t){return le(e,!1)}function Ve(e){var n=e.prototype;return!!(n&&n.isReactComponent)}function P(e,n,t){if(e==null)return\"\";if(typeof e==\"function\")return le(e,Ve(e));if(typeof e==\"string\")return U(e);switch(e){case I:return U(\"Suspense\");case F:return U(\"SuspenseList\")}if(typeof e==\"object\")switch(e.$$typeof){case R:return qe(e.render);case T:return P(e.type,n,t);case A:{var a=e,l=a._payload,d=a._init;try{return P(d(l),n,t)}catch{}}}return\"\"}var S=Object.prototype.hasOwnProperty,ue={},de=w.ReactDebugCurrentFrame;function O(e){if(e){var n=e._owner,t=P(e.type,e._source,n?n.type:null);de.setExtraStackFrame(t)}else de.setExtraStackFrame(null)}function Be(e,n,t,a,l){{var d=Function.call.bind(S);for(var o in e)if(d(e,o)){var s=void 0;try{if(typeof e[o]!=\"function\"){var _=Error((a||\"React class\")+\": \"+t+\" type `\"+o+\"` is invalid; it must be a function, usually from the `prop-types` package, but received `\"+typeof e[o]+\"`.This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.\");throw _.name=\"Invariant Violation\",_}s=e[o](n,o,a,t,null,\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\")}catch(c){s=c}s&&!(s instanceof Error)&&(O(l),b(\"%s: type specification of %s `%s` is invalid; the type checker function must return `null` or an `Error` but returned a %s. You may have forgotten to pass an argument to the type checker creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and shape all require an argument).\",a||\"React class\",t,o,typeof s),O(null)),s instanceof Error&&!(s.message in ue)&&(ue[s.message]=!0,O(l),b(\"Failed %s type: %s\",t,s.message),O(null))}}}var Ge=Array.isArray;function L(e){return Ge(e)}function Ke(e){{var n=typeof Symbol==\"function\"&&Symbol.toStringTag,t=n&&e[Symbol.toStringTag]||e.constructor.name||\"Object\";return t}}function ze(e){try{return ce(e),!1}catch{return!0}}function ce(e){return\"\"+e}function me(e){if(ze(e))return b(\"The provided key is an unsupported type %s. This value must be coerced to a string before before using it here.\",Ke(e)),ce(e)}var E=w.ReactCurrentOwner,Xe={key:!0,ref:!0,__self:!0,__source:!0},fe,be,$;$={};function He(e){if(S.call(e,\"ref\")){var n=Object.getOwnPropertyDescriptor(e,\"ref\").get;if(n&&n.isReactWarning)return!1}return e.ref!==void 0}function Je(e){if(S.call(e,\"key\")){var n=Object.getOwnPropertyDescriptor(e,\"key\").get;if(n&&n.isReactWarning)return!1}return e.key!==void 0}function Qe(e,n){if(typeof e.ref==\"string\"&&E.current&&n&&E.current.stateNode!==n){var t=v(E.current.type);$[t]||(b('Component \"%s\" contains the string ref \"%s\". Support for string refs will be removed in a future major release. This case cannot be automatically converted to an arrow function. We ask you to manually fix this case by using useRef() or createRef() instead. Learn more about using refs safely here: https://reactjs.org/link/strict-mode-string-ref',v(E.current.type),e.ref),$[t]=!0)}}function Ze(e,n){{var t=function(){fe||(fe=!0,b(\"%s: `key` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\",n))};t.isReactWarning=!0,Object.defineProperty(e,\"key\",{get:t,configurable:!0})}}function en(e,n){{var t=function(){be||(be=!0,b(\"%s: `ref` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\",n))};t.isReactWarning=!0,Object.defineProperty(e,\"ref\",{get:t,configurable:!0})}}var nn=function(e,n,t,a,l,d,o){var s={$$typeof:r,type:e,key:n,ref:t,props:o,_owner:d};return s._store={},Object.defineProperty(s._store,\"validated\",{configurable:!1,enumerable:!1,writable:!0,value:!1}),Object.defineProperty(s,\"_self\",{configurable:!1,enumerable:!1,writable:!1,value:a}),Object.defineProperty(s,\"_source\",{configurable:!1,enumerable:!1,writable:!1,value:l}),Object.freeze&&(Object.freeze(s.props),Object.freeze(s)),s};function rn(e,n,t,a,l){{var d,o={},s=null,_=null;t!==void 0&&(me(t),s=\"\"+t),Je(n)&&(me(n.key),s=\"\"+n.key),He(n)&&(_=n.ref,Qe(n,l));for(d in n)S.call(n,d)&&!Xe.hasOwnProperty(d)&&(o[d]=n[d]);if(e&&e.defaultProps){var c=e.defaultProps;for(d in c)o[d]===void 0&&(o[d]=c[d])}if(s||_){var m=typeof e==\"function\"?e.displayName||e.name||\"Unknown\":e;s&&Ze(o,m),_&&en(o,m)}return nn(e,s,_,l,a,E.current,o)}}var q=w.ReactCurrentOwner,_e=w.ReactDebugCurrentFrame;function x(e){if(e){var n=e._owner,t=P(e.type,e._source,n?n.type:null);_e.setExtraStackFrame(t)}else _e.setExtraStackFrame(null)}var V;V=!1;function B(e){return typeof e==\"object\"&&e!==null&&e.$$typeof===r}function he(){{if(q.current){var e=v(q.current.type);if(e)return`\n\nCheck the render method of \\``+e+\"`.\"}return\"\"}}function tn(e){{if(e!==void 0){var n=e.fileName.replace(/^.*[\\\\\\/]/,\"\"),t=e.lineNumber;return`\n\nCheck your code at `+n+\":\"+t+\".\"}return\"\"}}var pe={};function an(e){{var n=he();if(!n){var t=typeof e==\"string\"?e:e.displayName||e.name;t&&(n=`\n\nCheck the top-level render call using <`+t+\">.\")}return n}}function ve(e,n){{if(!e._store||e._store.validated||e.key!=null)return;e._store.validated=!0;var t=an(n);if(pe[t])return;pe[t]=!0;var a=\"\";e&&e._owner&&e._owner!==q.current&&(a=\" It was passed a child from \"+v(e._owner.type)+\".\"),x(e),b('Each child in a list should have a unique \"key\" prop.%s%s See https://reactjs.org/link/warning-keys for more information.',t,a),x(null)}}function ge(e,n){{if(typeof e!=\"object\")return;if(L(e))for(var t=0;t<e.length;t++){var a=e[t];B(a)&&ve(a,n)}else if(B(e))e._store&&(e._store.validated=!0);else if(e){var l=Pe(e);if(typeof l==\"function\"&&l!==e.entries)for(var d=l.call(e),o;!(o=d.next()).done;)B(o.value)&&ve(o.value,n)}}}function sn(e){{var n=e.type;if(n==null||typeof n==\"string\")return;var t;if(typeof n==\"function\")t=n.propTypes;else if(typeof n==\"object\"&&(n.$$typeof===R||n.$$typeof===T))t=n.propTypes;else return;if(t){var a=v(n);Be(t,e.props,\"prop\",a,e)}else if(n.PropTypes!==void 0&&!V){V=!0;var l=v(n);b(\"Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?\",l||\"Unknown\")}typeof n.getDefaultProps==\"function\"&&!n.getDefaultProps.isReactClassApproved&&b(\"getDefaultProps is only used on classic React.createClass definitions. Use a static property named `defaultProps` instead.\")}}function on(e){{for(var n=Object.keys(e.props),t=0;t<n.length;t++){var a=n[t];if(a!==\"children\"&&a!==\"key\"){x(e),b(\"Invalid prop `%s` supplied to `React.Fragment`. React.Fragment can only have `key` and `children` props.\",a),x(null);break}}e.ref!==null&&(x(e),b(\"Invalid attribute `ref` supplied to `React.Fragment`.\"),x(null))}}function ln(e,n,t,a,l,d){{var o=We(e);if(!o){var s=\"\";(e===void 0||typeof e==\"object\"&&e!==null&&Object.keys(e).length===0)&&(s+=\" You likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports.\");var _=tn(l);_?s+=_:s+=he();var c;e===null?c=\"null\":L(e)?c=\"array\":e!==void 0&&e.$$typeof===r?(c=\"<\"+(v(e.type)||\"Unknown\")+\" />\",s=\" Did you accidentally export a JSX literal instead of a component?\"):c=typeof e,b(\"React.jsx: type is invalid -- expected a string (for built-in components) or a class/function (for composite components) but got: %s.%s\",c,s)}var m=rn(e,n,t,l,d);if(m==null)return m;if(o){var h=n.children;if(h!==void 0)if(a)if(L(h)){for(var C=0;C<h.length;C++)ge(h[C],e);Object.freeze&&Object.freeze(h)}else b(\"React.jsx: Static children should always be an array. You are likely explicitly calling React.jsxs or React.jsxDEV. Use the Babel transform instead.\");else ge(h,e)}return e===p?on(m):sn(m),m}}var un=ln;K.Fragment=p,K.jsxDEV=un})()});var Ee=G((Dn,De)=>{\"use strict\";De.exports=Ce()});var Nn={};_n(Nn,{default:()=>yn,frontmatter:()=>vn});var i=hn(Ee()),vn={title:\"Whispers In The Background\",date:new Date(16828992e5),categories:[\"OpenAI\",\"ML\",\"Whisper\",\"MLE\"],description:\"A first stab at an architecture that allows for transcripts to be generated for user uploads\"};function Re(u){let r=Object.assign({h2:\"h2\",a:\"a\",span:\"span\",p:\"p\",ol:\"ol\",li:\"li\",h3:\"h3\",code:\"code\",div:\"div\",pre:\"pre\"},u.components),{KommyImage:f,Callout:p}=r;return p||Te(\"Callout\",!0,\"37:1-39:11\"),f||Te(\"KommyImage\",!0,\"12:1-12:171\"),(0,i.jsxDEV)(i.Fragment,{children:[(0,i.jsxDEV)(f,{blogImage:!0,src:\"https://user-images.githubusercontent.com/45760326/235455711-4dd33dde-88f9-456f-b5b5-c1c26e638576.png\",width:400,height:400},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:12,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.h2,{id:\"introduction\",children:[(0,i.jsxDEV)(r.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#introduction\",children:(0,i.jsxDEV)(r.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\"},this)},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\"},this),\"Introduction\"]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:14,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"I recently ran into two problems when trying to generate transcript for audio files using whisper when working with NextJS\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:16,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.ol,{children:[`\n`,(0,i.jsxDEV)(r.li,{children:\"They were taking too long and the request would time out\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:18,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.li,{children:\"The files were too large and I couldn't send them through the request body of a api route\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:19,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:18,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"If you're not familiar with NextJS deployed on Vercel, there are two limits that they place on your functions - they have to finish executing in at most 30s and the request body can't be larger than 4.5MB. You can try overriding body parser to take maybe 8mb of data but that's not a good idea since large audio files are often significantly larger than that.\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:21,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"I decided to try and solve this problem by using a long-running docker container which would act as a server and would be able to handle large files. I also decided to use a queue to handle the requests so that I could handle multiple requests at once.\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:23,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.h3,{id:\"database-as-a-queue\",children:[(0,i.jsxDEV)(r.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#database-as-a-queue\",children:(0,i.jsxDEV)(r.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\"},this)},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\"},this),\"Database-as-a-Queue\"]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:25,columnNumber:1},this),`\n`,(0,i.jsxDEV)(\"b\",{children:\"Here's the kicker - my database is my queue.\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:27,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:[\"I was inspired by \",(0,i.jsxDEV)(r.a,{href:\"https://www.prequel.co/blog/sql-maxis-why-we-ditched-rabbitmq-and-replaced-it-with-a-postgres-queue\",children:\"this article\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:29,columnNumber:19},this),\" I had read a while ago about how they had replaced RabbitMQ with Postgres and thought I'd be able to give it a shot too.\"]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:29,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"I came up with the following schema for a table which would be able to serve as our queue.\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:31,columnNumber:1},this),`\n`,(0,i.jsxDEV)(f,{src:\"https://user-images.githubusercontent.com/45760326/235456606-13ec3fb4-43da-4a10-ba62-89b275464b17.png\",width:400,height:400},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:33,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"Let's walk through a few important columnns.\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:35,columnNumber:1},this),`\n`,(0,i.jsxDEV)(p,{children:(0,i.jsxDEV)(r.p,{children:\"Note, I'm using ID because planetscale prevents the use of strings as primary keys\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:38,columnNumber:1},this)},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:37,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.ol,{children:[`\n`,(0,i.jsxDEV)(r.li,{children:[(0,i.jsxDEV)(r.code,{children:\"isProcesing\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:41,columnNumber:4},this),\" : This variable helps tell us when we started processing an item and how long it has been stuck processing an item for.\"]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:41,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.li,{children:[(0,i.jsxDEV)(r.code,{children:\"isProcessed\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:42,columnNumber:4},this),\" : This variable tells us if the item has been processed or not.\"]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:42,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.li,{children:[(0,i.jsxDEV)(r.code,{children:\"isTranscribed\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:43,columnNumber:4},this),\" : This variable tells us whether an item has been processed or not.\"]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:43,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.li,{children:[(0,i.jsxDEV)(r.code,{children:\"startedProcessing\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:44,columnNumber:4},this),\": This is a timestamp which tells us exactly when we started processing the current file.\"]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:44,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:41,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"So how do these variables help to ensure we have a queue?\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:46,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.ol,{children:[`\n`,(0,i.jsxDEV)(r.li,{children:[`\n`,(0,i.jsxDEV)(r.p,{children:[\"When a docker instance picks a item from the list to process, it sets \",(0,i.jsxDEV)(r.code,{children:\"isProcessing\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:48,columnNumber:74},this),\" to true and sets the \",(0,i.jsxDEV)(r.code,{children:\"processingStartedAt\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:48,columnNumber:110},this),\" to the current time. If another docker container happens to pick it up at the same time, it will see \",(0,i.jsxDEV)(r.code,{children:\"isProcessing\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:48,columnNumber:233},this),\" has been set to true and abandon the job.\"]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:48,columnNumber:4},this),`\n`]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:48,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.li,{children:[`\n`,(0,i.jsxDEV)(r.p,{children:[\"If it accidentally crashes or is unable to finish the processing, we have the \",(0,i.jsxDEV)(r.code,{children:\"startedProcessing\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:50,columnNumber:82},this),\" variable to tell us when exactly processing started. We can then specify a threshold, after which another docker instance can pick up the job even if \",(0,i.jsxDEV)(r.code,{children:\"isProcessing\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:50,columnNumber:252},this),\" is set to true.\"]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:50,columnNumber:4},this),`\n`]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:50,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.li,{children:[`\n`,(0,i.jsxDEV)(r.p,{children:\"if the file has already been transcribed, we can just end the job early.\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:52,columnNumber:4},this),`\n`]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:52,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:48,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"We can visualise this using a flowchart as seen below\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:54,columnNumber:1},this),`\n`,(0,i.jsxDEV)(f,{src:\"https://user-images.githubusercontent.com/45760326/235459095-efba6b62-27c9-460c-abfc-09c154a4a4bf.png\",blogImage:!0,height:400,width:400,alt:\"Decision Diagram for Server\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:56,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"Each of these jobs will always be completed by adding a cron job down the line which takes all the outstanding files which have been processing for more than a certain amount of time and sends them to be processed.\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:58,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"We can express this in psuedocode as follows\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:60,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.div,{\"data-rehype-pretty-code-fragment\":\"\",children:(0,i.jsxDEV)(r.pre,{\"data-language\":\"python\",\"data-theme\":\"default\",children:(0,i.jsxDEV)(r.code,{\"data-language\":\"python\",\"data-theme\":\"default\",children:(0,i.jsxDEV)(r.span,{className:\"line\",children:(0,i.jsxDEV)(r.span,{style:{color:\"#888888\"},children:\"# Get All Files that have isProcessing=false OR (isProcessing=True and startedProcessingAt > 30 minutes ago)\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:1,columnNumber:109},this)},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:1,columnNumber:90},this)},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:1,columnNumber:84},this)},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:1,columnNumber:1},this)},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:62,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"I might also add a retry counter which will help track the number of times a file has been attempted to be processed and if it has failed too many times, we can just mark it as failed and move on. Errors can then be shown to the user who might have uploaded a corrupted file.\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:66,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.h3,{id:\"fault-tolerance\",children:[(0,i.jsxDEV)(r.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#fault-tolerance\",children:(0,i.jsxDEV)(r.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\"},this)},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\"},this),\"Fault Tolerance\"]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:68,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"I built this to tolerate two main kinds of faults\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:70,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.ol,{children:[`\n`,(0,i.jsxDEV)(r.li,{children:[`\n`,(0,i.jsxDEV)(r.p,{children:\"Docker Containers going down - If a file is being processed midway and our docker container dies, a cron job will identify all the files that need to be processed easily and retry them\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:72,columnNumber:4},this),`\n`]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:72,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.li,{children:[`\n`,(0,i.jsxDEV)(r.p,{children:\"File Information being captured - we capture a succesful upload at two different locations. The first is on the user's side after they get notified that they have a succesful upload. The second is on that of AWS S3. By adding in a trigger to automatically start processing the file upon uploading it to S3, we can ensure that we have a backup of the file in case something goes wrong.\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:74,columnNumber:4},this),`\n`]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:74,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:72,columnNumber:1},this),`\n`,(0,i.jsxDEV)(r.p,{children:\"That's a quick writeup on what I found most interesting about this specific project. I'll be writing a more detailed post about how I built this and certain parts in the future so stay tuned!\"},void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:77,columnNumber:2},this)]},void 0,!0,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\",lineNumber:1,columnNumber:1},this)}function gn(u={}){let{wrapper:r}=u.components||{};return r?(0,i.jsxDEV)(r,Object.assign({},u,{children:(0,i.jsxDEV)(Re,u,void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\"},this)}),void 0,!1,{fileName:\"/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx\"},this):Re(u)}var yn=gn;function Te(u,r,f){throw new Error(\"Expected \"+(r?\"component\":\"object\")+\" `\"+u+\"` to be defined: you likely forgot to import, pass, or provide it.\"+(f?\"\\nIt\\u2019s referenced in your code at `\"+f+\"` in `/Users/ivanleo/Documents/Coding/website_v3/posts/_mdx_bundler_entry_point-081ea690-03e1-427d-bba7-187c5c08479e.mdx`\":\"\"))}return pn(Nn);})();\n/*! Bundled license information:\n\nreact/cjs/react-jsx-dev-runtime.development.js:\n  (**\n   * @license React\n   * react-jsx-dev-runtime.development.js\n   *\n   * Copyright (c) Facebook, Inc. and its affiliates.\n   *\n   * This source code is licensed under the MIT license found in the\n   * LICENSE file in the root directory of this source tree.\n   *)\n*/\n;return Component;"
  },
  "_id": "whispers-in-the-background.mdx",
  "_raw": {
    "sourceFilePath": "whispers-in-the-background.mdx",
    "sourceFileName": "whispers-in-the-background.mdx",
    "sourceFileDir": ".",
    "contentType": "mdx",
    "flattenedPath": "whispers-in-the-background"
  },
  "type": "Post",
  "url": "/posts/whispers-in-the-background",
  "slug": "whispers_in_the_background",
  "parsed_date": "May 01, 2023",
  "parsed_tags": [
    {
      "name": "OpenAI",
      "slug": "openai"
    },
    {
      "name": "ML",
      "slug": "ml"
    },
    {
      "name": "Whisper",
      "slug": "whisper"
    },
    {
      "name": "MLE",
      "slug": "mle"
    }
  ]
}